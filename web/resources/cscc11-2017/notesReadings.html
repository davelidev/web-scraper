
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML>
<HEAD><TITLE>CSCC11: Introduction to Machine Learning and Data Mining</TITLE>
<META http-equiv=Content-Type content="text/html; charset=iso-8859-1">
<META content="MSHTML 6.00.2800.1276" name=GENERATOR></TITLE>
<STYLE type=text/css>BODY {
        BACKGROUND: white; MARGIN-LEFT: 5%; COLOR: black;
        MARGIN-RIGHT: 10%; FONT-FAMILY: sans-serif
}
H1 {
        FONT-FAMILY: sans-serif
}
H2 {
        FONT-FAMILY: sans-serif
}
H3 {
        FONT-FAMILY: sans-serif; TEXT-DECORATION: underline
}

</STYLE>
</HEAD>
<BODY bgColor=#ffffff>
<H2>
Readings / Notes:
<A href="index.html">CSCC11 Introduction to Machine Learning and Data Mining </A>
</H2>


<body>

The links to chapters of the notes that have not yet been covered in lecture may be broken.<br><br>

</td></tr><tr><td>
Front matter:</td> <td><a href="Handouts/FrontMatter.pdf">Title page, table of contents, notation</a></td></tr></table>

<BR>
<BR>


<table border="1" cellpadding="10">

<tbody><tr> 
<td width="25"><strong>Chapter </strong></td>
<td width="250"><strong>Notes</strong></td>
<td width="280"><strong>Contents</strong></td>
<td width="280"><strong>Links and Other Readings</strong></td>
</tr>

<tr>
 <td><strong> 1.  </strong></td>
 <td> <a href="Handouts/Introduction.pdf">Introduction to Machine Learning</a></td>
 </td>
 <td> Overview of Machine Learning topics
 </td>
 <td valign="top">
        <a href="http://en.wikipedia.org/wiki/Machine_Learning">Machine Learning (Wikipedia)</a><br />
        <a href="Handouts/linalg.pdf">Linear Algebra Review (by Z. Kolter)</a><br />
  </td>
</tr>

<tr> 
 <td><strong> 2.  </strong></td> 
 <td> <a href="Handouts/LinearRegression.pdf">Linear Regression</a></td> 
 </td>
 <td> 1D regression,<br> multidimensional regression,<br> 
      least-squares, pseudo-inverse
 </td>
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/Linear_Regression">Linear Regresion (Wikipedia)</a><br />
  </td>
</tr>


<tr> 
 <td><strong> 3.  </strong></td> 
 <td> <a href="Handouts/NonlinearRegression.pdf">Nonlinear Regression</a></td> 
 </td>
 <td> Basis function regression, Radial Basis Functions, Neural networks, K-nearest nieghbours
 </td>
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/Radial_basis_function">RBFs (Wikipedia)</a> <br />
	<a href="http://en.wikipedia.org/wiki/Artificial_neural_network">ANNs (Wikipedia)</a><br />
	<a href="http://en.wikipedia.org/wiki/Nearest_neighbor_(pattern_recognition)">KNN (Wikipedia)</a> <br />
  </td>
</tr>


<tr>
 <td><strong> 4.  </strong></td>
 <td> <a href="Handouts/Quadratics.pdf">Quadratics (background)</a></td>
 </td>
 <td> Matrix-vector quadratic forms, gradients, optimization <br>
 <td valign="top">
        <a href="Handouts/linalg.pdf">Linear Algebra Review (by Z. Kolter)</a><br />
 </td>
</tr>

<tr> 
 <td><strong> 5.  </strong></td> 
 <td> <a href="Handouts/ProbabilityTheory.pdf">Basic Probability and Statistics (background)</a></td> 
 </td>
 <td valign="top"> Probability, conditioning, marginalization, density, mathematical expectation
 </td>
 <td valign="top"> 
	<a href="http://en.wikipedia.org/wiki/Cox%27s_theorem"> Cox axioms (wikipedia)</a><br>
	<a href="http://en.wikipedia.org/wiki/Binomial_distribution"> binomial distribution (wikipedia)</a><br>
	<a href="http://en.wikipedia.org/wiki/Multinomial_distribution"> multinomial distribution (wikipedia)</a>
 </td>
</tr>

<tr> 
 <td><strong> 6.  </strong></td> 
 <td> <a href="Handouts/PDFs.pdf">Probability Density Functions (background)</a></td> 
 </td>
 <td valign="top"> 
	PDFs Mean and covariance, Uniform distribution, (multi-dim.) 
        Gaussian distribution
 </td> 
 <td valign="top"><a href="http://en.wikipedia.org/wiki/Probability_density_function">PDFs (Wikipedia)</a> <br>
 	<a href="Handouts/probReview.pdf">Probability Review (by S. Teong)</a><br />
 </td>
</tr>

<tr> 
 <td><strong> 7.  </strong></td> 
 <td> <a href="Handouts/Estimation.pdf">Estimation</a></td> 
 </td>
 <td valign="top"> 
	Bayes' rule, Maximum likelihood, Maximum a Posteriori
 </td> 
 <td valign="top"> 
 	<a href="Handouts/ProbabilityandLS_NG.pdf">Probabilistic LS (by A. Ng)</a><br />
 </td>
</tr>

<tr>
 <td><strong> 8.  </strong></td>
 <td> <a href="Handouts/Classification.pdf">Introduction to Classification</a></td>
 </td>
 <td valign="top">
        Class conditional models, Logistic regression,
        Neural Network Classifiers, Na&iuml;ve Bayes
 </td>
 <td valign="top">
        <a href="http://en.wikipedia.org/wiki/Logistic_regression">Logistic
        Regression (Wikipedia)</a><br />
        <a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier">Na&iuml;ve
        Bayes (Wikipedia)</a><br />
 </td>
</tr>

<tr> 
 <td><strong> 9.  </strong></td> 
 <td> <a href="Handouts/GradientDescent.pdf">Gradient Descent (background)</a></td> 
 </td>
 <td valign="top"> 
	Gradient Descent, Line Search
 </td> 
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/Gradient_descent">Gradient descent (Wikipedia)</a><br />
	<a href="http://en.wikipedia.org/wiki/Line_search">Line Search (Wikipedia)</a><br />
	<a href="http://en.wikipedia.org/wiki/Optimization_%28mathematics%29">Optimization (Wikipedia)</a><br />
 </td>
</tr>


<tr> 
 <td><strong> 10.  </strong></td> 
 <td> <a href="Handouts/CrossValidation.pdf">Cross Validation </a></td> 
 </td>
 <td valign="top"> 
	Hold-out Validation, N-Fold Cross Valiadation
 </td> 
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/Cross_validation">Cross-validation (Wikipedia)</a><br />
 </td>
</tr>


<tr>
 <td><strong> 11.  </strong></td>
 <td> <a href="Handouts/BayesianMethods.pdf">Bayesian Methods </a></td>
 </td>
 <td valign="top">
        Bayesian Regression, Model Averaging, Model Selection
 </td>
 <td valign="top">
        <a href="http://alumni.media.mit.edu/~tpminka/statlearn/demo/">Bayesian model selection demos (Tom Minka)</a>
 </td>
</tr>


<tr>
 <td><strong> 12.  </strong></td>
 <td> <a href="Handouts/MonteCarloMethods.pdf">Monte Carlo Methods (optional) </a></
td>
 </td>
 <td valign="top">
        Sampling Gaussians, Importance Sampling, MCMC, Metropolis Hastings
 </td>
 <td valign="top">
        <a href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC (Wikipedia)</a><br />
        <a href="http://www.lbreyer.com/classic.html">MCMC applet</a>
 </td>
</tr>


<tr>
 <td><strong> 13.  </strong></td>
 <td> <a href="Handouts/PCA.pdf">Principal Component Analysis</a></td>
 </td>
 <td valign="top">
	Dimensionality Reduction, PCA, Probabilistic PCA (optional), 
        Whitening (optional)
 </td>
 <td valign="top">
        <a href="http://en.wikipedia.org/wiki/Karhunen-Lo%C3%A8ve_transform">PCA (Wikipedia)</a> <br />
        <a href="Handouts/pca-smithTutorial.pdf">Introductory PCA Tutorial (by L. Sm
ith)</a>
 </td>
</tr>


<tr>
 <td><strong> 14.  </strong></td>
 <td> <a href="Handouts/LagrangeMultipliers.pdf">Lagrange Multipliers (background) </a></td>
 </td>
 <td valign="top">
        Equality constraints, Bounds constraints
 </td>
 <td valign="top">
       <a href="http://en.wikipedia.org/wiki/Lagrange_multipliers">Lagrange Multipliers (Wikipedia)</a>
 </td>
</tr>


<tr>
 <td><strong> 15.  </strong></td>
 <td> <a href="Handouts/Clustering.pdf">Clustering</a></td>
 </td>
 <td valign="top">
        K-means, Mixtures of Gaussians, Expectation-Maximization Algorithm
 </td>
 <td valign="top">
       <a href="http://en.wikipedia.org/wiki/K-means_clustering">K-means (Wikipedia)</a><br/>
        <a href="Handouts/mixtureModel.pdf">Slides on Mixture Models and EM</a><br/>
        <a href="Handouts/BIC.pdf">Notes on BIC</a>
 </td>
</tr>

<tr> 
 <td><strong> 16.  </strong></td> 
 <td> <a href="Handouts/HiddenMarkovModels.pdf">Hiddden Markov Models (optional)</a></td> 
 </td>
 <td valign="top"> 
	Markov chains, Viterbi, Forward-Backward, Baum-Welch (EM)
 </td> 
 <td valign="top">
       <a href="http://en.wikipedia.org/wiki/Hidden_Markov_model">HMMs (Wikipedia)</a>
 </td>
</tr>


<tr> 
 <td><strong> 17.  </strong></td> 
 <td> <a href="Handouts/SupportVectorMachines.pdf">Support Vector Machines</a></td> 
 </td>
 <td valign="top"> 
	Maximum margin, Loss functions, Kernels
 </td> 
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/Support_vector_machine">SVMs (Wikipedia)</a>
 </td>
</tr>


<tr> 
 <td><strong> 18.  </strong></td> 
 <td> <a href="Handouts/AdaBoost.pdf">AdaBoost </a></td> 
 </td>
 <td valign="top"> 
	Boosting, Ensemble Methods,
 </td> 
 <td valign="top">
	<a href="http://en.wikipedia.org/wiki/AdaBoost">AdaBoost (Wikipedia)</a>
 </td>
</tr>


</table>


</div>

</body>
</html>

